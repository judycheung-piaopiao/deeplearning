{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b845ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0820.jpg' -1]\n",
      " ['0418.jpg' -1]\n",
      " ['0704.jpg' -1]\n",
      " ...\n",
      " ['1653.jpg' -1]\n",
      " ['2607.jpg' -1]\n",
      " ['2732.jpg' -1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg\n",
    "import sklearn as skl\n",
    "import random as rdm\n",
    "import pickle as pkl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications.xception import Xception\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from datetime import datetime\n",
    "\n",
    "data = pd.read_csv(\"D:/Personal/Downloads/bitmoji-faces-gender-recognition(1)/train.csv\")\n",
    "path = \"D:/Personal/Downloads/bitmoji-faces-gender-recognition(1)/trainimages/\"\n",
    "path_test = \"D:/Personal/Downloads/bitmoji-faces-gender-recognition(1)/testimages/\"\n",
    "y = data['is_male']\n",
    "x = data['image_id']\n",
    "x_test, x_val_name, y_test, y_val_single = train_test_split(x, y, test_size=0.1, random_state=0)\n",
    "x_y = np.stack((x_test, y_test), axis=1)\n",
    "print(x_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1662af60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 384, 384, 3) (300, 2)\n"
     ]
    }
   ],
   "source": [
    "x_val = list()\n",
    "for i in x_val_name:\n",
    "    x_tmp = mpimg.imread(path + i).astype(np.float64)\n",
    "    x_tmp /= 255\n",
    "    x_val.append(x_tmp)\n",
    "y_val = list()\n",
    "for i in y_val_single:\n",
    "    y_tmp = [1, 0] if i == 1 else [0, 1]\n",
    "    y_val.append(y_tmp)\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31683646",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_batch = 0\n",
    "max_batch = 27\n",
    "def data_generator():\n",
    "    global count_batch\n",
    "    while 1:\n",
    "        if count_batch == max_batch:\n",
    "            count_batch = 0\n",
    "            rdm.shuffle(x_y)\n",
    "        x_batch = list()\n",
    "        y_batch = list()\n",
    "        for i in range(100):\n",
    "            tmp = count_batch*100+i\n",
    "            x = mpimg.imread(path + x_y[tmp][0]).astype(np.float64)\n",
    "            x /= 255\n",
    "            x_batch.append(x)\n",
    "            y = [1, 0] if x_y[tmp][1] == 1 else [0, 1]\n",
    "            y_batch.append(y)\n",
    "        count_batch += 1\n",
    "        x_batch = np.array(x_batch)\n",
    "        y_batch = np.array(y_batch)\n",
    "        yield(x_batch, y_batch)\n",
    "count_val = 0\n",
    "max_val = 3\n",
    "def val_generator():\n",
    "    global count_val\n",
    "    while 1:\n",
    "        if count_val == max_val:\n",
    "            count_val = 0\n",
    "        x_ = x_val[100*count_val:100*(count_val + 1) - 1]\n",
    "        y_ = y_val[100*count_val:100*(count_val + 1) - 1]\n",
    "        count_val += 1\n",
    "        yield(x_, y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3306affe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_base = Xception(weights=\"imagenet\", include_top=False, input_shape=(384,384,3))\n",
    "mx = conv_base.output\n",
    "mx = GlobalAveragePooling2D()(mx)\n",
    "mx = Dense(1024, activation='relu')(mx)\n",
    "predictions = Dense(2, activation='softmax')(mx)\n",
    "model = Model(inputs=conv_base.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66ebea44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
      "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Personal\\Temp/ipykernel_16340/4188707335.py:8: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history_pretrain = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.3456 - acc: 0.8841\n",
      "Epoch 1: val_loss improved from inf to 0.19523, saving model to D:/Personal/Downloads/bitmoji-faces-gender-recognition(1)\\model_pretrain_01-0.1952.hdf5\n",
      "27/27 [==============================] - 261s 10s/step - loss: 0.3456 - acc: 0.8841 - val_loss: 0.1952 - val_acc: 0.9567\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1758 - acc: 0.9374\n",
      "Epoch 2: val_loss did not improve from 0.19523\n",
      "27/27 [==============================] - 257s 10s/step - loss: 0.1758 - acc: 0.9374 - val_loss: 0.2254 - val_acc: 0.9300\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0996 - acc: 0.9693\n",
      "Epoch 3: val_loss improved from 0.19523 to 0.13567, saving model to D:/Personal/Downloads/bitmoji-faces-gender-recognition(1)\\model_pretrain_03-0.1357.hdf5\n",
      "27/27 [==============================] - 256s 10s/step - loss: 0.0996 - acc: 0.9693 - val_loss: 0.1357 - val_acc: 0.9600\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0530 - acc: 0.9815\n",
      "Epoch 4: val_loss improved from 0.13567 to 0.07909, saving model to D:/Personal/Downloads/bitmoji-faces-gender-recognition(1)\\model_pretrain_04-0.0791.hdf5\n",
      "27/27 [==============================] - 258s 10s/step - loss: 0.0530 - acc: 0.9815 - val_loss: 0.0791 - val_acc: 0.9733\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0569 - acc: 0.9815\n",
      "Epoch 5: val_loss did not improve from 0.07909\n",
      "27/27 [==============================] - 256s 10s/step - loss: 0.0569 - acc: 0.9815 - val_loss: 0.0806 - val_acc: 0.9733\n"
     ]
    }
   ],
   "source": [
    "conv_base.trainable = False\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=2, verbose=1, mode='auto', restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint('D:/Personal/Downloads/bitmoji-faces-gender-recognition(1)/model_pretrain_{epoch:02d}-{val_loss:.4f}.hdf5', monitor='val_loss', \\\n",
    "                             verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "tensorboard = TensorBoard(log_dir='D:/Personal/Downloads/bitmoji-faces-gender-recognition(1)', histogram_freq=1, batch_size=max_batch, write_graph=False, write_grads=True, \\\n",
    "                          write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='batch')\n",
    "history_pretrain = model.fit_generator(\n",
    "    generator=data_generator(),\n",
    "    steps_per_epoch=max_batch,\n",
    "    epochs=5,\n",
    "    max_queue_size=1,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[early_stopping, checkpoint, tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8242dcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
      "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "D:\\Personal\\Temp/ipykernel_16340/3403848809.py:14: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0041 - acc: 0.9996\n",
      "Epoch 1: val_loss improved from inf to 0.08058, saving model to D:/Personal/Downloads/bitmoji-faces-gender-recognition(1)\\model_01-0.0806.hdf5\n",
      "27/27 [==============================] - 258s 10s/step - loss: 0.0041 - acc: 0.9996 - val_loss: 0.0806 - val_acc: 0.9733\n",
      "Epoch 2/20\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 2: val_loss did not improve from 0.08058\n",
      "27/27 [==============================] - 255s 9s/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0806 - val_acc: 0.9733\n",
      "Epoch 3/20\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 3: val_loss did not improve from 0.08058\n",
      "27/27 [==============================] - 255s 9s/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0806 - val_acc: 0.9733\n",
      "Epoch 4/20\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 4: val_loss did not improve from 0.08058\n",
      "27/27 [==============================] - 255s 9s/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0806 - val_acc: 0.9733\n",
      "Epoch 5/20\n",
      "27/27 [==============================] - ETA: 0s - loss: 9.8861e-04 - acc: 1.0000\n",
      "Epoch 5: val_loss did not improve from 0.08058\n",
      "27/27 [==============================] - 255s 9s/step - loss: 9.8861e-04 - acc: 1.0000 - val_loss: 0.0806 - val_acc: 0.9733\n",
      "Epoch 6/20\n",
      "27/27 [==============================] - ETA: 0s - loss: 9.7820e-04 - acc: 1.0000Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.08058\n",
      "27/27 [==============================] - 255s 9s/step - loss: 9.7820e-04 - acc: 1.0000 - val_loss: 0.0806 - val_acc: 0.9733\n",
      "Epoch 6: early stopping\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers[:369]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[369:]:\n",
    "   layer.trainable = True\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='binary_crossentropy', metrics=['acc'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint('D:/Personal/Downloads/bitmoji-faces-gender-recognition(1)/model_{epoch:02d}-{val_loss:.4f}.hdf5', monitor='val_loss', \\\n",
    "                             verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "tensorboard = TensorBoard(log_dir='D:/Personal/Downloads/bitmoji-faces-gender-recognition(1)/logs/train', histogram_freq=1, batch_size=max_batch, write_graph=True, write_grads=True, \\\n",
    "                          write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='batch')\n",
    "\n",
    "history = model.fit_generator(\n",
    "    generator=data_generator(),\n",
    "    steps_per_epoch=max_batch,\n",
    "    epochs=20,\n",
    "    max_queue_size=1,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[early_stopping, checkpoint, tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6daa2334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain history:\n",
      "[0, 1, 2, 3, 4]\n",
      "{'loss': [0.3455744683742523, 0.17575480043888092, 0.09956318885087967, 0.052954334765672684, 0.0569339394569397], 'acc': [0.8840740919113159, 0.9374074339866638, 0.9692592620849609, 0.9814814925193787, 0.9814814925193787], 'val_loss': [0.19522732496261597, 0.22536863386631012, 0.13567139208316803, 0.07909020036458969, 0.08058354258537292], 'val_acc': [0.9566666483879089, 0.9300000071525574, 0.9599999785423279, 0.9733333587646484, 0.9733333587646484]}\n",
      "train history:\n",
      "[0, 1, 2, 3, 4, 5]\n",
      "{'loss': [0.004084461834281683, 0.0017228772630915046, 0.0012780835386365652, 0.0010434341384097934, 0.0009886093903332949, 0.0009782016277313232], 'acc': [0.9996296167373657, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.08058354258537292, 0.08058354258537292, 0.08058354258537292, 0.08058354258537292, 0.08058354258537292, 0.08058354258537292], 'val_acc': [0.9733333587646484, 0.9733333587646484, 0.9733333587646484, 0.9733333587646484, 0.9733333587646484, 0.9733333587646484]}\n"
     ]
    }
   ],
   "source": [
    "print(\"pretrain history:\")\n",
    "print(history_pretrain.epoch)\n",
    "print(history_pretrain.history)\n",
    "print(\"train history:\")\n",
    "print(history.epoch)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5322552",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pretrain_history.pkl\", 'wb') as fp:\n",
    "    pkl.dump(history_pretrain.history, fp)\n",
    "with open(\"history.pkl\", 'wb') as fp:\n",
    "    pkl.dump(history_pretrain.history, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed138bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"D:/Personal/Downloads/bitmoji-faces-gender-recognition(1)/train/\"  + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb238e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"D:/Personal/Downloads/bitmoji-faces-gender-recognition(1)/sample_submission.csv\")\n",
    "test_name = test['image_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650bc51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = list()\n",
    "for name in test_name:\n",
    "    x_tmp = mpimg.imread(path_test + name).astype(np.float64)\n",
    "    x_tmp /= 255\n",
    "    x_test.append(x_tmp)\n",
    "x_test = np.array(x_test)\n",
    "print(x_test.shape)\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afd0bb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.5440769e-04 9.9984562e-01]\n",
      " [3.6155087e-01 6.3844919e-01]\n",
      " [1.5866364e-08 1.0000000e+00]\n",
      " ...\n",
      " [9.9999523e-01 4.7433446e-06]\n",
      " [1.0017332e-08 1.0000000e+00]\n",
      " [9.9999499e-01 4.9848909e-06]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4ff4b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      image_id is_male\n",
      "0     3000.jpg      -1\n",
      "1     3001.jpg      -1\n",
      "2     3002.jpg      -1\n",
      "3     3003.jpg       1\n",
      "4     3004.jpg      -1\n",
      "...        ...     ...\n",
      "1079  4079.jpg      -1\n",
      "1080  4080.jpg       1\n",
      "1081  4081.jpg       1\n",
      "1082  4082.jpg      -1\n",
      "1083  4083.jpg       1\n",
      "\n",
      "[1084 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "result = pd.DataFrame(columns=['image_id', 'is_male'])\n",
    "for i in range(1084):\n",
    "    x = test_name[i]\n",
    "    y = '1' if y_pred[i][0] > y_pred[i][1] else '-1'\n",
    "    x_y = {'image_id':x, 'is_male':y}\n",
    "    result = result.append(x_y, ignore_index=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30929213",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='D:/Personal/Downloads/bitmoji-faces-gender-recognition(1)/submission.csv'\n",
    "result.to_csv(file_name, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
